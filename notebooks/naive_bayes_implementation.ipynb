{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division # ensure that all division is float division\n",
    "from __future__ import print_function # print function works properly when used with paranthesis\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, sys, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read in SMS Data.**\n",
    "\n",
    ">The SMS Spam Collection v.1 is a public set of SMS labeled messages that have been collected for mobile phone spam research. It has one collection composed by 5,574 English, real and non-enconded messages, tagged according being legitimate (ham) or spam.\n",
    "\n",
    ">A collection of 425 SMS spam messages was manually extracted from the Grumbletext Web site. This is a UK forum in which cell phone users make public claims about SMS spam messages, most of them without reporting the very spam message received. The identification of the text of spam messages in the claims is a very hard and time-consuming task, and it involved carefully scanning hundreds of web pages. The Grumbletext Web site is: http://www.grumbletext.co.uk/.\n",
    "\n",
    ">A subset of 3,375 SMS randomly chosen ham messages of the NUS SMS Corpus (NSC), which is a dataset of about 10,000 legitimate messages collected for research at the Department of Computer Science at the National University of Singapore. The messages largely originate from Singaporeans and mostly from students attending the University. These messages were collected from volunteers who were made aware that their contributions were going to be made publicly available. The NUS SMS Corpus is avalaible at: http://www.comp.nus.edu.sg/~rpnlpir/downloads/corpora/smsCorpus/.\n",
    "\n",
    "\n",
    "- Primary Source: http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/\n",
    "- Secondary: https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&amp;C's apply 08452810075over18's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                                                                                       message  \n",
       "0                                              Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...  \n",
       "1                                                                                                                                Ok lar... Joking wif u oni...  \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's  \n",
       "3                                                                                                            U dun say so early hor... U c already then say...  \n",
       "4                                                                                                Nah I don't think he goes to usf, he lives around here though  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/sms.tsv\", sep=\"\\t\", names=['label', 'message'])\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stratified means the proprtions of spam/ham in the train/test sets reflect the original dataset. You can see the percentage is about the same here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5293, 2) (279, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.86586057056489707, 0.86738351254480284)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "train, test = train_test_split(df, test_size=0.05, stratify=df.label)\n",
    "print(train.shape, test.shape)\n",
    "train.label.value_counts()['ham'] / len(train), test.label.value_counts()['ham'] / len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create sample data frame and sample rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract two sample messages that we will use for testing in the functions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham | No it's waiting in e car dat's bored wat. Cos wait outside got nothing 2 do. At home can do my stuff or watch tv wat.\n",
      "ham | Stupid.its not possible\n"
     ]
    }
   ],
   "source": [
    "sample_df = train.sample(2)\n",
    "\n",
    "sample_row1 = sample_df.iloc[0] # first row of sample_df\n",
    "sample_row2 = sample_df.iloc[1] # second row of sample_df\n",
    "\n",
    "sample_message1 = sample_row1.message\n",
    "sample_message2 = sample_row2.message\n",
    "\n",
    "print(sample_row1.label, \"|\", sample_message1)\n",
    "print(sample_row2.label, \"|\", sample_message2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize Message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use http://regex101.com to come up with regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No it's waiting in e car dat's bored wat. Cos wait outside got nothing 2 do. At home can do my stuff or watch tv wat.\n",
      "Stupid.its not possible\n",
      "['at', 'in', 'home', 'no', 'tv', \"it's\", \"dat's\", 'waiting', 'outside', 'got', 'wat', 'do', 'watch', 'nothing', 'wait', 'cos', 'bored', 'car', 'stuff', 'can', 'my', 'or']\n",
      "['not', 'stupid', 'its', 'possible']\n"
     ]
    }
   ],
   "source": [
    "def tokenize(msg):\n",
    "    \"\"\"\n",
    "    input: \"Change again... It's e one next to escalator...\"\n",
    "    output: [\"change\", \"again\", \"it's\", \"one\", \"next\", \"to\", \"escalator\"]\n",
    "    \"\"\"\n",
    "    msg_lowered = msg.lower()\n",
    "    # at least two characters long, cannot start with number\n",
    "    all_tokens = re.findall(r\"\\b[a-z][a-z0-9']+\\b\", msg_lowered)\n",
    "    return list(set(all_tokens))\n",
    "\n",
    "tokens1 = tokenize(sample_message1)\n",
    "tokens2 = tokenize(sample_message2)\n",
    "\n",
    "print(sample_message1)\n",
    "print(sample_message2)\n",
    "\n",
    "print(tokens1)\n",
    "print(tokens2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize Message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Walk through the steps of vectorizing a message outside of a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Message 1: No it's waiting in e car dat's bored wat. Cos wait outside got nothing 2 do. At home can do my stuff or watch tv wat.\n",
      "Tokens 1: ['at', 'in', 'home', 'no', 'tv', \"it's\", \"dat's\", 'waiting', 'outside', 'got', 'wat', 'do', 'watch', 'nothing', 'wait', 'cos', 'bored', 'car', 'stuff', 'can', 'my', 'or']\n",
      "Series 1:\n",
      "at         1\n",
      "bored      1\n",
      "can        1\n",
      "car        1\n",
      "cos        1\n",
      "dat's      1\n",
      "do         1\n",
      "got        1\n",
      "home       1\n",
      "in         1\n",
      "it's       1\n",
      "my         1\n",
      "no         1\n",
      "nothing    1\n",
      "or         1\n",
      "outside    1\n",
      "stuff      1\n",
      "tv         1\n",
      "wait       1\n",
      "waiting    1\n",
      "wat        1\n",
      "watch      1\n",
      "dtype: int64\n",
      "\n",
      "Sample Message 2: Stupid.its not possible\n",
      "Tokens 2: ['not', 'stupid', 'its', 'possible']\n",
      "Series 2:\n",
      "its         1\n",
      "not         1\n",
      "possible    1\n",
      "stupid      1\n",
      "dtype: int64\n",
      "\n",
      "Combine Series 1 and Series 2:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>at</th>\n",
       "      <th>bored</th>\n",
       "      <th>can</th>\n",
       "      <th>car</th>\n",
       "      <th>cos</th>\n",
       "      <th>dat's</th>\n",
       "      <th>do</th>\n",
       "      <th>got</th>\n",
       "      <th>home</th>\n",
       "      <th>in</th>\n",
       "      <th>...</th>\n",
       "      <th>or</th>\n",
       "      <th>outside</th>\n",
       "      <th>possible</th>\n",
       "      <th>stuff</th>\n",
       "      <th>stupid</th>\n",
       "      <th>tv</th>\n",
       "      <th>wait</th>\n",
       "      <th>waiting</th>\n",
       "      <th>wat</th>\n",
       "      <th>watch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   at  bored  can  car  cos  dat's  do  got  home  in  ...    or  outside  \\\n",
       "0   1      1    1    1    1      1   1    1     1   1  ...     1        1   \n",
       "1   0      0    0    0    0      0   0    0     0   0  ...     0        0   \n",
       "\n",
       "   possible  stuff  stupid  tv  wait  waiting  wat  watch  \n",
       "0         0      1       0   1     1        1    1      1  \n",
       "1         1      0       1   0     0        0    0      0  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_dict1 = {} # this is a dictionary that looks like {word1: 1, word2: 1, word3: 1}\n",
    "for token in tokens1:\n",
    "    token_dict1[token] = 1 \n",
    "series1 = pd.Series(token_dict1) # convert the dictionary into a series where the row labels are words\n",
    "\n",
    "# rewrite the same as above using a dict comprehension\n",
    "series1 = pd.Series({token: 1 for token in tokens1})\n",
    "\n",
    "token_dict2 = {} # this is a dictionary that looks like {word1: 1, word2: 1, word3: 1}\n",
    "for token in tokens2:\n",
    "    token_dict2[token] = 1 \n",
    "series2 = pd.Series(token_dict2) # convert the dictionary into a series where the row labels are words\n",
    "\n",
    "# rewrite the same as above using a dict comprehension\n",
    "series2 = pd.Series({token: 1 for token in tokens2})\n",
    "\n",
    "print(\"Sample Message 1:\", sample_message1)\n",
    "print(\"Tokens 1:\", tokens1)\n",
    "print(\"Series 1:\")\n",
    "print(series1)\n",
    "print()\n",
    "print(\"Sample Message 2:\", sample_message2)\n",
    "print(\"Tokens 2:\", tokens2)\n",
    "print(\"Series 2:\")\n",
    "print(series2)\n",
    "print()\n",
    "\n",
    "print(\"Combine Series 1 and Series 2:\")\n",
    "df2 = pd.DataFrame([series1, series2]) # comebine the two \n",
    "df2.fillna(0, inplace=True)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the same process as above of tokenzing and then vectorizing using a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize_row(row):\n",
    "    \"\"\"\n",
    "    input: row in data frame with a \".message\" attribute\n",
    "    output: vectorized row where the row labels are words and the values are 1 for each row\n",
    "    \"\"\"\n",
    "    message = row.message\n",
    "    tokens = tokenize(message)\n",
    "    vectorized_row = pd.Series({token: 1 for token in tokens})\n",
    "    return vectorized_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "at         1\n",
       "bored      1\n",
       "can        1\n",
       "car        1\n",
       "cos        1\n",
       "dat's      1\n",
       "do         1\n",
       "got        1\n",
       "home       1\n",
       "in         1\n",
       "it's       1\n",
       "my         1\n",
       "no         1\n",
       "nothing    1\n",
       "or         1\n",
       "outside    1\n",
       "stuff      1\n",
       "tv         1\n",
       "wait       1\n",
       "waiting    1\n",
       "wat        1\n",
       "watch      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_row(sample_row1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "its         1\n",
       "not         1\n",
       "possible    1\n",
       "stupid      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_row(sample_row2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Feature Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is input to our Naive Bayes model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feature_matrix(df):\n",
    "    feature_matrix = df.apply(vectorize_row, axis=1)\n",
    "    feature_matrix.fillna(0, inplace=True)\n",
    "    return feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>at</th>\n",
       "      <th>bored</th>\n",
       "      <th>can</th>\n",
       "      <th>car</th>\n",
       "      <th>cos</th>\n",
       "      <th>dat's</th>\n",
       "      <th>do</th>\n",
       "      <th>got</th>\n",
       "      <th>home</th>\n",
       "      <th>in</th>\n",
       "      <th>...</th>\n",
       "      <th>or</th>\n",
       "      <th>outside</th>\n",
       "      <th>possible</th>\n",
       "      <th>stuff</th>\n",
       "      <th>stupid</th>\n",
       "      <th>tv</th>\n",
       "      <th>wait</th>\n",
       "      <th>waiting</th>\n",
       "      <th>wat</th>\n",
       "      <th>watch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      at  bored  can  car  cos  dat's  do  got  home  in  ...    or  outside  \\\n",
       "506    1      1    1    1    1      1   1    1     1   1  ...     1        1   \n",
       "1454   0      0    0    0    0      0   0    0     0   0  ...     0        0   \n",
       "\n",
       "      possible  stuff  stupid  tv  wait  waiting  wat  watch  \n",
       "506          0      1       0   1     1        1    1      1  \n",
       "1454         1      0       1   0     0        0    0      0  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_feature_matrix(sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5293, 7795)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix = get_feature_matrix(train)\n",
    "feature_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'a21', u'a30', u'aa', u'aah', u'aaniye', u'aaooooright', u'aathi',\n",
       "       u'ab', u'abbey', u'abdomen', u'abeg', u'abel', u'aberdeen', u'abi',\n",
       "       u'ability', u'abiola', u'abj', u'able', u'abnormally', u'about',\n",
       "       u'aboutas', u'above', u'abroad', u'absence', u'absolutely',\n",
       "       u'absolutly', u'abstract', u'abt', u'abta', u'aburo', u'abuse',\n",
       "       u'abusers', u'ac', u'acc', u'accent', u'accenture', u'accept',\n",
       "       u'access', u'accessible', u'accidant', u'accident', u'accidentally',\n",
       "       u'accommodation', u'accommodationvouchers', u'accomodate',\n",
       "       u'accomodations', u'accordin', u'accordingly', u'account',\n",
       "       u'account's'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix.columns[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'ym', u'yo', u'yoga', u'yogasana', u'yor', u'yorge', u'you', u'you'd',\n",
       "       u'you'll', u'you're', u'you've', u'youdoing', u'youi', u'young',\n",
       "       u'younger', u'youphone', u'your', u'your's', u'youre', u'yourinclusive',\n",
       "       u'yourjob', u'yours', u'yourself', u'youuuuu', u'youwanna', u'yoville',\n",
       "       u'yowifes', u'yoyyooo', u'yr', u'yrs', u'ystrday', u'yummmm', u'yummy',\n",
       "       u'yun', u'yunny', u'yuo', u'yuou', u'yup', u'yupz', u'zac', u'zebra',\n",
       "       u'zed', u'zeros', u'zhong', u'zindgi', u'zoe', u'zogtorius', u'zoom',\n",
       "       u'zouk', u'zyada'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix.columns[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a21</th>\n",
       "      <th>a30</th>\n",
       "      <th>aa</th>\n",
       "      <th>aah</th>\n",
       "      <th>aaniye</th>\n",
       "      <th>aaooooright</th>\n",
       "      <th>aathi</th>\n",
       "      <th>ab</th>\n",
       "      <th>abbey</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>...</th>\n",
       "      <th>zebra</th>\n",
       "      <th>zed</th>\n",
       "      <th>zeros</th>\n",
       "      <th>zhong</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3938</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2976</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4088</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2136</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7795 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      a21  a30  aa  aah  aaniye  aaooooright  aathi  ab  abbey  abdomen  \\\n",
       "3938    0    0   0    0       0            0      0   0      0        0   \n",
       "2976    0    0   0    0       0            0      0   0      0        0   \n",
       "891     0    0   0    0       0            0      0   0      0        0   \n",
       "4088    0    0   0    0       0            0      0   0      0        0   \n",
       "2136    0    0   0    0       0            0      0   0      0        0   \n",
       "\n",
       "      ...    zebra  zed  zeros  zhong  zindgi  zoe  zogtorius  zoom  zouk  \\\n",
       "3938  ...        0    0      0      0       0    0          0     0     0   \n",
       "2976  ...        0    0      0      0       0    0          0     0     0   \n",
       "891   ...        0    0      0      0       0    0          0     0     0   \n",
       "4088  ...        0    0      0      0       0    0          0     0     0   \n",
       "2136  ...        0    0      0      0       0    0          0     0     0   \n",
       "\n",
       "      zyada  \n",
       "3938      0  \n",
       "2976      0  \n",
       "891       0  \n",
       "4088      0  \n",
       "2136      0  \n",
       "\n",
       "[5 rows x 7795 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Feature Probabilities (Train/Fit Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conditional probability of each word is given [additive smoothing](https://en.wikipedia.org/wiki/Additive_smoothing) below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_conditional_probability_for_word(col, k=0.5):\n",
    "    return (col.sum() + k) / (len(col) + 2*k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feature_prob(feature_matrix):\n",
    "    \n",
    "    spam_boolean_mask = (df.label == \"spam\")\n",
    "    ham_boolean_mask = (df.label == \"ham\")\n",
    "    \n",
    "    # Explanation for \"confusing\" syntax:\n",
    "    # http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
    "    \n",
    "    feature_matrix_spam = feature_matrix.loc[spam_boolean_mask, :] # get all rows for spam boolean mask\n",
    "    feature_matrix_ham = feature_matrix.loc[ham_boolean_mask, :] # get all rows for ham boolean mask\n",
    "    \n",
    "    # mymatrix[:, 0] is to get the first column\n",
    "    # mymatrix[:, 1] is to get the second column\n",
    "    \n",
    "    # mymatrix[0, :] is to get the first row\n",
    "    # mymatrix[1, :] is to get the second row\n",
    "    \n",
    "    # mymatrix[boolean_mask, :] is to get the rows where boolean_mask is True\n",
    "    \n",
    "    feature_prob_spam = feature_matrix_spam.apply(get_conditional_probability_for_word, axis=0)\n",
    "    feature_prob_ham = feature_matrix_ham.apply(get_conditional_probability_for_word, axis=0)\n",
    "    \n",
    "    feature_prob = pd.concat([feature_prob_spam, feature_prob_ham], axis=1)\n",
    "    feature_prob.columns = ['spam', 'ham']\n",
    "    \n",
    "    return feature_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7795, 2)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_prob = get_feature_prob(feature_matrix)\n",
    "feature_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>ham</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a21</th>\n",
       "      <td>0.002110</td>\n",
       "      <td>0.000109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a30</th>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.000327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aa</th>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.000327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aah</th>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.000764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaniye</th>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.000327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            spam       ham\n",
       "a21     0.002110  0.000109\n",
       "a30     0.000703  0.000327\n",
       "aa      0.000703  0.000327\n",
       "aah     0.000703  0.000764\n",
       "aaniye  0.000703  0.000327"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_prob.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Feature Probabilities in Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words with the largest conditional probability for predicting spam.\n",
    "\n",
    "P(w_i | y= \"spam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>ham</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0.622363</td>\n",
       "      <td>0.252072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>call</th>\n",
       "      <td>0.436709</td>\n",
       "      <td>0.045921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you</th>\n",
       "      <td>0.315752</td>\n",
       "      <td>0.269306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>your</th>\n",
       "      <td>0.307314</td>\n",
       "      <td>0.074498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>now</th>\n",
       "      <td>0.259494</td>\n",
       "      <td>0.060100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>or</th>\n",
       "      <td>0.239803</td>\n",
       "      <td>0.045266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>0.238397</td>\n",
       "      <td>0.091950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>free</th>\n",
       "      <td>0.232771</td>\n",
       "      <td>0.012544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.228551</td>\n",
       "      <td>0.180083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt</th>\n",
       "      <td>0.200422</td>\n",
       "      <td>0.002945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          spam       ham\n",
       "to    0.622363  0.252072\n",
       "call  0.436709  0.045921\n",
       "you   0.315752  0.269306\n",
       "your  0.307314  0.074498\n",
       "now   0.259494  0.060100\n",
       "or    0.239803  0.045266\n",
       "for   0.238397  0.091950\n",
       "free  0.232771  0.012544\n",
       "the   0.228551  0.180083\n",
       "txt   0.200422  0.002945"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_prob.sort_values(by='spam', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words with the smallest conditional probability for predicting ham.\n",
    "\n",
    "P(w_i | y= \"ham\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>ham</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a21</th>\n",
       "      <td>0.002110</td>\n",
       "      <td>0.000109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ree</th>\n",
       "      <td>0.002110</td>\n",
       "      <td>0.000109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daytime</th>\n",
       "      <td>0.002110</td>\n",
       "      <td>0.000109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ref</th>\n",
       "      <td>0.006329</td>\n",
       "      <td>0.000109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dating</th>\n",
       "      <td>0.023207</td>\n",
       "      <td>0.000109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datebox1282essexcm61xn</th>\n",
       "      <td>0.003516</td>\n",
       "      <td>0.000109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refused</th>\n",
       "      <td>0.004923</td>\n",
       "      <td>0.000109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regalportfolio</th>\n",
       "      <td>0.002110</td>\n",
       "      <td>0.000109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dartboard</th>\n",
       "      <td>0.002110</td>\n",
       "      <td>0.000109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regard</th>\n",
       "      <td>0.002110</td>\n",
       "      <td>0.000109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            spam       ham\n",
       "a21                     0.002110  0.000109\n",
       "ree                     0.002110  0.000109\n",
       "daytime                 0.002110  0.000109\n",
       "ref                     0.006329  0.000109\n",
       "dating                  0.023207  0.000109\n",
       "datebox1282essexcm61xn  0.003516  0.000109\n",
       "refused                 0.004923  0.000109\n",
       "regalportfolio          0.002110  0.000109\n",
       "dartboard               0.002110  0.000109\n",
       "regard                  0.002110  0.000109"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_prob.sort_values(by='ham', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Takeaway**: These models are trained looking only at one class at a time, so the largest conditional probabilities may end up being common stop words. However, this will occur in both classes which ends up \"cancelling out\". The stop words won't predict one way or the other. Instead, looking at the least predictive words of the opposite class - in this case the words least predictive of \"ham\" will show us highly predictive spam words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>spam</td>\n",
       "      <td>URGENT! We are trying to contact U. Todays draw shows that you have won a £800 prize GUARANTEED. Call 09050001295 from land line. Claim A21. Valid 12hrs only</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label  \\\n",
       "1673  spam   \n",
       "\n",
       "                                                                                                                                                            message  \n",
       "1673  URGENT! We are trying to contact U. Todays draw shows that you have won a £800 prize GUARANTEED. Call 09050001295 from land line. Claim A21. Valid 12hrs only  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.message.str.contains(\"a21\", case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4373</th>\n",
       "      <td>spam</td>\n",
       "      <td>Ur balance is now £600. Next question: Complete the landmark, Big, A. Bob, B. Barry or C. Ben ?. Text A, B or C to 83738. Good luck!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label  \\\n",
       "4373  spam   \n",
       "\n",
       "                                                                                                                                   message  \n",
       "4373  Ur balance is now £600. Next question: Complete the landmark, Big, A. Bob, B. Barry or C. Ben ?. Text A, B or C to 83738. Good luck!  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.message.str.contains(\"landmark\", case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>spam</td>\n",
       "      <td>Bored housewives! Chat n date now! 0871750.77.11! BT-national rate 10p/min only from landlines!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4864</th>\n",
       "      <td>spam</td>\n",
       "      <td>Bored housewives! Chat n date now! 0871750.77.11! BT-national rate 10p/min only from landlines!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label  \\\n",
       "3998  spam   \n",
       "4864  spam   \n",
       "\n",
       "                                                                                              message  \n",
       "3998  Bored housewives! Chat n date now! 0871750.77.11! BT-national rate 10p/min only from landlines!  \n",
       "4864  Bored housewives! Chat n date now! 0871750.77.11! BT-national rate 10p/min only from landlines!  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.message.str.contains(\"landlines\", case=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label                                                                                 ham\n",
       "message    Just checking in on you. Really do miss seeing Jeremiah. Do have a great month\n",
       "Name: 350, dtype: object"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_spam_prob(row):\n",
    "    \n",
    "    new_msg = row.message\n",
    "    \n",
    "    tokens = tokenize(new_msg)\n",
    "    \n",
    "    log_prob_if_spam = 0.0\n",
    "    log_prob_if_not_spam = 0.0\n",
    "    \n",
    "    for word, prob in feature_prob.iterrows():\n",
    "        \n",
    "        prob_if_spam = prob.spam\n",
    "        prob_if_not_spam = prob.ham\n",
    "        \n",
    "        if word in tokens:\n",
    "            log_prob_if_spam += math.log(prob_if_spam)\n",
    "            log_prob_if_not_spam += math.log(prob_if_not_spam)\n",
    "        else:\n",
    "            log_prob_if_spam += math.log(1.0 - prob_if_spam)\n",
    "            log_prob_if_not_spam += math.log(1.0 - prob_if_not_spam)\n",
    "        \n",
    "    prob_if_spam = math.exp(log_prob_if_spam)\n",
    "    prob_if_not_spam = math.exp(log_prob_if_not_spam)\n",
    "        \n",
    "    return prob_if_spam / (prob_if_spam + prob_if_not_spam)\n",
    "    \n",
    "#     return pd.Series({\n",
    "#         \"spam_prob\": prob_if_spam, #/ (prob_if_spam + prob_if_not_spam), \n",
    "#         \"ham_prob\": prob_if_not_spam #/ (prob_if_spam + prob_if_not_spam)\n",
    "#     })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test_probs = test.apply(get_spam_prob, axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
